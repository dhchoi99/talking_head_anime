{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc27eb9",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "You can train Talking Head Anime with two different type of datasets:\n",
    "\n",
    "1. Images Dataset (recommended)\n",
    "2. 3D-models Dataset\n",
    "\n",
    "If you don't have appropriate dataset, you may want to follow instructions below or write your own dataset code with your data.\n",
    "\n",
    "If you have any, or have own code for your dataset, you may skip these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42ff28",
   "metadata": {},
   "source": [
    "### Images dataset:\n",
    "\n",
    "* set of images consist of (model_base, model_shaped, model_shaped_rotated) pairs.\n",
    "* Detailed description of pairs:\n",
    "    * model_base: Image of model with rest(base) pose. `base.png`\n",
    "    * model_shaped: Image of model with its face parts' shape changed. `shape_0.57_0.0_0.5.png`\n",
    "    * model_shaped_rotated: Image of model of `model_shaped`'s head rotated with XYZ\n",
    "      axis.`pose_0.57_0.0_0.5_0.41_-0.68_1.png`\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th> Type </th>\n",
    "    <th width=256>Model base</th>\n",
    "    <th width=256>Model shaped</th>\n",
    "    <th width=256>Model shaped rotated</th> \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th> Description </th>\n",
    "    <td> Rendered Image of a 3d model with rest pose </td>\n",
    "    <td> Rendered Image of a 3d model with its face expression changed. <br> Mouth: 0.57 open, Left eye: 0.0 closed, Right eye: 0.5 closed. </td>\n",
    "    <td> Rendered Image of a 3d model with its face expression changed, and then head rotated. <br> Mouth: 0.57 open, Left eye: 0.0 closed, Right eye: 0.5 closed. <br> Head rotated  with x axis: 0.41 pi/2, y_axis: -0.68 pi/2, z_axis: 1 pi/2 </td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "    <th> Image </th>\n",
    "    <td><img src=\"src/images/base.png?v=1\" width=256/></td> \n",
    "    <td><img src=\"src/images/shape_0.57_0.0_0.5.png\" width=256/></td> \n",
    "    <td><img src=\"src/images/pose_0.57_0.0_0.5_0.41_-0.68_1.png\" width=256/></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05eb557",
   "metadata": {},
   "source": [
    "### 3D-models dataset:\n",
    "\n",
    "Note that 3D-models dataset may suffer with extermely low speed when training.\n",
    "\n",
    "* Set of models where each files' extension is one of `.pmx`, `.pmd` or `.vrm`.\n",
    "\n",
    "Example:\n",
    "```\n",
    "[dhchoi@localhost 3d_models]$ cat all_blends.txt | head -3\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10003__こんにゃく式戌亥とこver1.0/こんにゃく式戌亥とこver1.0/戌亥とこ.pmx\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール(帽子無し).pmx\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール.pmx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a0fd1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38d281",
   "metadata": {},
   "source": [
    "## Downloading 3D Models\n",
    "\n",
    "Here, we'll download 3D models and filter usable models for Talking Head Anime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb800c",
   "metadata": {},
   "source": [
    "### Downloading 3D models\n",
    "\n",
    "I batch-crawled 3d models from [3d.nicovideo.jp](3d.nicovideo.jp) and [bowlroll.net](bowlroll.net) to `./data/3d_models/models`.  \n",
    "\n",
    "Each models(or projects) are seperated into directories. Naming convention is not a big problem unless you(and your code) can classify those.\n",
    "\n",
    "**Since there must exist copyright issue, I will not provide the download script.**\n",
    "\n",
    "Downloading the models took about 1~2 days, resulting with about 60000 projects.\n",
    "\n",
    "Example:\n",
    "```\n",
    "(blender_py37) root@d0277a12bc8c:~/talking_head_anime_2# ls -al data/3d_models/models/ | head -7\n",
    "total 4396\n",
    "drwxr-xr-x 30157 31004 31000 1789952 Jan 28 18:31 .\n",
    "drwxr-xr-x    10 31004 31000    4096 Feb 23 03:57 ..\n",
    "drwxr-xr-x     3 31004 31000      60 Dec 24 00:20 3d.nicovideo__10002__ニュイ・ソシエール(部屋着)\n",
    "drwxr-xr-x     3 31004 31000      58 Dec 24 00:20 3d.nicovideo__10003__こんにゃく式戌亥とこver1.0\n",
    "drwxr-xr-x     3 31004 31000      73 Dec 24 00:20 3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00\n",
    "drwxr-xr-x     3 31004 31000      40 Dec 24 00:20 3d.nicovideo__10029__大阪ステージ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f260",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca51eae",
   "metadata": {},
   "source": [
    "## Filtering Dataset (1)\n",
    "\n",
    "For convinience, I used projects which used `.pmx`, `.pmd` or `.vrm` file.\n",
    "\n",
    "After running the cells, I had about 30000 projects supporting `.pmd`, `.pmx`, or `.vrm` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a0c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def find_model_in_dir(dir_model: str):\n",
    "    \"\"\" searches if dir_model has loadable file\n",
    "\n",
    "    Args:\n",
    "        dir_model: root dir to find loadable file\n",
    "\n",
    "    Returns:\n",
    "        result: Boolean. True if exists, else False\n",
    "        path_model: str. if result is true, valid model path is given. Else returns ''\n",
    "\n",
    "    \"\"\"\n",
    "    result = False\n",
    "    result_path = ''\n",
    "    for root, subdirs, files in os.walk(dir_model):\n",
    "        for file in files:\n",
    "            path_model = os.path.join(root, file)\n",
    "            if file.endswith('.pmx'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "            elif file.endswith('.pmd'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "            elif file.endswith('.vrm'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "\n",
    "        if result:\n",
    "            break\n",
    "\n",
    "    return result, result_path\n",
    "\n",
    "\n",
    "def find_valid_dirs(dir_root: str):\n",
    "    \"\"\" finds subdir names which contains loadable files (.pmx, .pmd, .vrm)\n",
    "\n",
    "    Args:\n",
    "        dir_root: root dir to search\n",
    "        path_save: path to save indices\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    models = sorted([os.path.join(dir_root, file) for file in os.listdir(dir_root)\n",
    "                     if os.path.isdir(os.path.join(dir_root, file))])\n",
    "\n",
    "    pmxs = []\n",
    "    pmds = []\n",
    "    vrms = []\n",
    "\n",
    "    for dir_model in tqdm(models):\n",
    "        result_bool, result_path = find_model_in_dir(dir_model)\n",
    "        if result_bool:\n",
    "            if result_path.endswith('.pmx'):\n",
    "                pmxs.append(dir_model)\n",
    "            elif result_path.endswith('.pmd'):\n",
    "                pmds.append(dir_model)\n",
    "            elif result_path.endswith('.vrm'):\n",
    "                vrms.append(dir_model)\n",
    "\n",
    "    print(len(models), len(pmxs), len(pmds), len(vrms))\n",
    "\n",
    "    valid_list = sorted(pmxs + pmds + vrms)\n",
    "    return valid_list\n",
    "\n",
    "\n",
    "dir_root = './data/3d_models/models'\n",
    "dir_projects = find_valid_dirs(dir_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d157ed8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7aa0fe",
   "metadata": {},
   "source": [
    "## Filtering dataset (2)\n",
    "\n",
    "* First, non-human shaped models should be filtered out.\n",
    "* Second, since original *Talking Head Anime* used 6 parameters(`Left eye`, `Right eye`, `Mouth`, `Head X`, `Head Y`, `Neck Z`), models not containing such keys should be filtered out.\n",
    "    * Although `.pmx`, `.pmd`, `.vrm` is common and standard-like model and it is easy to figure out that using `あ`, `ウィンク`, `ウィンク右` and `頭`(or `頸`) is enough, but...\n",
    "    * Some models use different keys. (e.g. some are translated to other language that is not `janapese`(standard)) \n",
    "    * To make sure, we'll extract shape keys and pose keys from all model files and analyze them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096e740",
   "metadata": {},
   "source": [
    "### Finding all models from projects\n",
    "\n",
    "Some projects include more than one models. (Usually cloth or accessories changed/added)\n",
    "\n",
    "We find all `.pmd`, `.pmx`, `.vrm` files to enlarge training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a21b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_all_models(dir_projects):\n",
    "    all_models = []\n",
    "    for dir_project in tqdm(dir_projects):\n",
    "        models_in_dir = []\n",
    "\n",
    "        for root, subdirs, files in os.walk(dir_project):\n",
    "            for file in files:\n",
    "                path_model = os.path.abspath(os.path.join(root, file))\n",
    "                extension = file.rsplit('.', 1)[-1].lower()\n",
    "                if extension == 'pmd' or extension == 'pmx' or extension == 'vrm':\n",
    "                    if path_model not in models_in_dir:\n",
    "                        models_in_dir.append(path_model)\n",
    "        \n",
    "        all_models.extend(models_in_dir)\n",
    "\n",
    "    return all_models\n",
    "\n",
    "path_models = find_all_models(dir_projects)\n",
    "print(len(dir_projects), len(path_models))\n",
    "\n",
    "with open('data/3d_models/all_models.txt', 'w', encoding='utf-8') as f:\n",
    "    write_data = [item+'\\n' for item in path_models]\n",
    "    f.writelines(write_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c78b1",
   "metadata": {},
   "source": [
    "### Saving models into .blend files\n",
    "\n",
    "While extracting shape keys and pose keys, saving each model files into `.blend` file is helpful for later convenient use.\n",
    "\n",
    "* `.blend` files can be loaded faster than loading from scratch with addons. \n",
    "* If once saved as `.blend` format, addons are not needed when loading & rendering `.blend` file.\n",
    "\n",
    "The script below will save loadable models to `.blend` files, at `data/3d_models/blends`.\n",
    "\n",
    "**!!Before running!!** \n",
    "* This is a long and painful process. Try to adjust number of processes available with your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c686ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m utils.data.run_blends --processes 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657b543",
   "metadata": {},
   "source": [
    "### Analysis of shape keys, pose keys\n",
    "\n",
    "First, pair each key and models.\n",
    "\n",
    "#### Find all .blend files\n",
    "\n",
    "Using successfully saved `.blend` files helps to keep away from unexpected bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all blend files\n",
    "\n",
    "def find_all_blends(blend_dir):\n",
    "    all_blends = []\n",
    "    dirnames = os.listdir(blend_dir)\n",
    "    for dirname in tqdm(dirnames):\n",
    "        dir_model = os.path.join(blend_dir, dirname)\n",
    "        blends_in_dir = []\n",
    "        \n",
    "        for root, subdirs, files in os.walk(dir_model):    \n",
    "            for file in files:\n",
    "                path_model = os.path.join(root, file)\n",
    "                extension = file.rsplit('.', 1)[-1].lower()\n",
    "                if extension == 'blend':\n",
    "                    if path_model not in blends_in_dir:\n",
    "                        blends_in_dir.append(path_model)\n",
    "        \n",
    "        all_blends.extend(blends_in_dir)\n",
    "\n",
    "    return all_blends\n",
    "\n",
    "all_blends = find_all_blends(blend_dir='data/3d_models/blends')\n",
    "print(len(all_blends))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056b3e77",
   "metadata": {},
   "source": [
    "#### Count keys\n",
    "For every key, pair key with list of models using the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_keys(path_blends):\n",
    "    shapes = defaultdict(list)\n",
    "    poses = defaultdict(list)\n",
    "    \n",
    "    for path_blend in tqdm(path_blends):\n",
    "        path_shape = path_blend[:-6] + '.shape.txt'\n",
    "        with open(path_shape, 'r', encoding='utf-8') as f:\n",
    "            shape_keys = f.readlines()\n",
    "        for line in shape_keys:\n",
    "            key = line.strip()\n",
    "            shapes[key].append(path_blend)\n",
    "            \n",
    "        path_pose = path_blend[:-6] + '.pose.txt'            \n",
    "        with open(path_pose, 'r', encoding='utf-8') as f:\n",
    "            pose_keys = f.readlines()\n",
    "        for line in pose_keys:\n",
    "            key = line.strip()\n",
    "            poses[key].append(path_blend)\n",
    "    \n",
    "    return shapes, poses\n",
    "\n",
    "shapes, poses = count_keys(all_blends)\n",
    "shape_counts = [f'{key}, {len(value)}\\n' for key, value in shapes.items()]\n",
    "shape_counts = sorted(shape_counts, key=lambda x: int(x.strip().rsplit(', ')[-1]), reverse=True)\n",
    "with open('data/3d_models/all_shapes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(shape_counts)\n",
    "\n",
    "\n",
    "pose_counts = [f'{key}, {len(value)}\\n' for key, value in poses.items()]\n",
    "pose_counts = sorted(pose_counts, key=lambda x: int(x.strip().rsplit(', ')[-1]), reverse=True)\n",
    "with open('data/3d_models/all_poses.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(pose_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3dc6e9",
   "metadata": {},
   "source": [
    "#### Analyze keys\n",
    "\n",
    "Check `data/3d_models/all_shapes.txt`, `data/3d_models/all_poses.txt` and check for most frequently used keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/3d_models/all_shapes.txt | head -10\n",
    "print('########')\n",
    "!cat data/3d_models/all_poses.txt | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089359a",
   "metadata": {},
   "source": [
    "As expected, `あ`, `ウィンク`, `ウィンク右` and `頭` is the most general keys and using them would be enough.\n",
    "* `あ` is much more used than `a` and amount of `a` could be ignored.\n",
    "* `頭` is more common compared to `頸`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262bcbc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23702e8",
   "metadata": {},
   "source": [
    "## Filtering dataset (3)\n",
    "\n",
    "It is not guaranteed for a model to properly work with `あ`, `ウィンク`, `ウィンク右` and `頭`.\n",
    "\n",
    "For example, somes models may move its left eye with key(eye on the right when rendered at image) `ウィンク右`(meaning right wink), while others may move models' right eye.\n",
    "\n",
    "Filtering and adjusting them is important proess in dataset generation. Sadly, such filtering could be best done with pure human effort. In this process, we render sample images from models and classify those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e220768",
   "metadata": {},
   "source": [
    "#### Generating Sample Images\n",
    "\n",
    "First, find blendfiles supporting all `あ`, `ウィンク`, `ウィンク右` and `頭`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2411731",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_blends = list(set.intersection(set(shapes['あ']), set(shapes['ウィンク']), set(shapes['ウィンク右']), set(poses['頭'])))\n",
    "with open('data/3d_models/all_valid_blends.txt', 'w', encoding='utf-8') as f:\n",
    "    write_lines = [item+'\\n' for item in all_valid_blends]\n",
    "    f.writelines(write_lines)\n",
    "print(len(all_valid_blends))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57869633",
   "metadata": {},
   "source": [
    "Then, Generate samples. The script below will save sample images to `data/3d_models/samples`.\n",
    "\n",
    "**!!Before running!!** \n",
    "* This is a long and painful process. Try to adjust number of processes available with your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m utils.data.run_samples --processes 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93d873",
   "metadata": {},
   "source": [
    "#### Checking Generated Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14f995",
   "metadata": {},
   "source": [
    "**TODO: I'll try to make this runnable at ipynb.**\n",
    "\n",
    "I used custom filtering helper tool to label the data.\n",
    "\n",
    "You may use `python -m utils.data.filter_tool3` if you have gui in your device. Else, you should use your own method to check the samples.\n",
    "\n",
    "1. run `python -m utils.data.filter_tool3` at the root of the project.\n",
    "2. If the model is closing left eye at the second image, PRESS `L`.\n",
    "3. If the model is closing right eye at the second image, PRESS `R`.\n",
    "4. You can leave without saving with pressing `q`.\n",
    "5. If there is some error on rendered images, PRESS `any other key` listed above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4218ff",
   "metadata": {},
   "source": [
    "After checking sample images, you get `data/3d_models/filtered_idxs.txt`.\n",
    "\n",
    "Each line of the result text file must be as `<BLENDFILE_PATH | LABEL> `.\n",
    "\n",
    "Result example:\n",
    "```\n",
    "(blender_py37) root@d0277a12bc8c:~/talking_head_anime_2# cat data/3d_models/filtered_idxs.txt | head -10\n",
    "data/3d_models/blends/3d.nicovideo__10035__xismoda-kun/xismoda-kun/鱚茂田_陽_tall.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10056__Amemori_Sayo_v1.1/Amemori_Sayo_v1.1/雨森小夜v1.1.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10039__大神ミオ(パーカーあり・なし)/大神ミオ(パーカーあり・なし)/ookamimio_with_hoodie.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10034__ﾏﾝﾊｯﾀﾝP式雨森小夜%2Bver1.1/ﾏﾝﾊｯﾀﾝP式雨森小夜 ver1.1/ﾏﾝﾊｯﾀﾝP式雨森小夜 ver1.1.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール(帽子無し).pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10055__てゐ/てゐ.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10039__大神ミオ(パーカーあり・なし)/大神ミオ(パーカーあり・なし)/ookamimio_without_hoodie.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10003__こんにゃく式戌亥とこver1.0/こんにゃく式戌亥とこver1.0/戌亥とこ.pmx.blend|L\n",
    "data/3d_models/blends/3d.nicovideo__10056__Amemori_Sayo_v1.1/Amemori_Sayo_v1.1/雨森小夜v1.1_toonあり.pmx.blend|L\n",
    "```\n",
    "\n",
    "Now we will generate training dataset based on the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d438b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f267d4",
   "metadata": {},
   "source": [
    "## Generating Training Dataset\n",
    "\n",
    "Now we generate image dataset for tranining *Talking Head Anime*.\n",
    "\n",
    "**!!Before running!!** \n",
    "* This is the longest and most painful process in this notebook. Try to adjust number of processes available with your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf59a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m utils.data.generate_dataset --processes 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793507f8",
   "metadata": {},
   "source": [
    "Now with `data/3d_models/filtered_idxs.txt` and `data/3d_models/imgset`, we are ready to train *Talking Head Anime*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}