{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc27eb9",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "You can train Talking Head Anime with two different type of datasets:\n",
    "\n",
    "1. Images Dataset (recommended)\n",
    "2. 3D-models Dataset\n",
    "\n",
    "If you don't have appropriate dataset, you may want to follow instructions below or write your own dataset code with your data.\n",
    "\n",
    "If you have any, or have own code for your dataset, you may skip these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42ff28",
   "metadata": {},
   "source": [
    "### Images dataset:\n",
    "\n",
    "* set of images consist of (model_base, model_shaped, model_shaped_rotated) pairs.\n",
    "* Detailed description of pairs:\n",
    "    * model_base: Image of model with rest(base) pose. `base.png`\n",
    "    * model_shaped: Image of model with its face parts' shape changed. `shape_0.57_0.0_0.5.png`\n",
    "    * model_shaped_rotated: Image of model of `model_shaped`'s head rotated with XYZ\n",
    "      axis.`pose_0.57_0.0_0.5_0.41_-0.68_1.png`\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th> Type </th>\n",
    "    <th width=256>Model base</th>\n",
    "    <th width=256>Model shaped</th>\n",
    "    <th width=256>Model shaped rotated</th> \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th> Description </th>\n",
    "    <td> Rendered Image of a 3d model with rest pose </td>\n",
    "    <td> Rendered Image of a 3d model with its face expression changed. <br> Mouth: 0.57 open, Left eye: 0.0 closed, Right eye: 0.5 closed. </td>\n",
    "    <td> Rendered Image of a 3d model with its face expression changed, and then head rotated. <br> Mouth: 0.57 open, Left eye: 0.0 closed, Right eye: 0.5 closed. <br> Head rotated  with x axis: 0.41 pi/2, y_axis: -0.68 pi/2, z_axis: 1 pi/2 </td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "    <th> Image </th>\n",
    "    <td><img src=\"src/images/base.png?v=1\" width=256/></td> \n",
    "    <td><img src=\"src/images/shape_0.57_0.0_0.5.png\" width=256/></td> \n",
    "    <td><img src=\"src/images/pose_0.57_0.0_0.5_0.41_-0.68_1.png\" width=256/></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05eb557",
   "metadata": {},
   "source": [
    "### 3D-models dataset:\n",
    "\n",
    "Note that 3D-models dataset may suffer with extermely low speed when training.\n",
    "\n",
    "* Set of models where each files' extension is one of `.pmx`, `.pmd` or `.vrm`.\n",
    "\n",
    "Example:\n",
    "```\n",
    "[dhchoi@localhost 3d_models]$ cat all_blends.txt | head -3\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10003__こんにゃく式戌亥とこver1.0/こんにゃく式戌亥とこver1.0/戌亥とこ.pmx\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール(帽子無し).pmx\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール.pmx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a0fd1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38d281",
   "metadata": {},
   "source": [
    "## Downloading 3D Models\n",
    "\n",
    "Here, we'll download 3D models and filter usable models for Talking Head Anime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb800c",
   "metadata": {},
   "source": [
    "### Downloading 3D models\n",
    "\n",
    "I batch-crawled 3d models from [3d.nicovideo.jp](3d.nicovideo.jp) and [bowlroll.net](bowlroll.net) to `./data/3d_models/models`.  \n",
    "\n",
    "Each models(or projects) are seperated into directories. Naming convention is not a big problem unless you(and your code) can classify those.\n",
    "\n",
    "**Since there must exist copyright issue, I will not provide the download script.**\n",
    "\n",
    "Downloading the models took about 1~2 days, resulting with about 60000 projects.\n",
    "\n",
    "Example:\n",
    "```\n",
    "(blender_py37) root@d0277a12bc8c:~/talking_head_anime_2# ls -al data/3d_models/models/ | head -7\n",
    "total 4396\n",
    "drwxr-xr-x 30157 31004 31000 1789952 Jan 28 18:31 .\n",
    "drwxr-xr-x    10 31004 31000    4096 Feb 23 03:57 ..\n",
    "drwxr-xr-x     3 31004 31000      60 Dec 24 00:20 3d.nicovideo__10002__ニュイ・ソシエール(部屋着)\n",
    "drwxr-xr-x     3 31004 31000      58 Dec 24 00:20 3d.nicovideo__10003__こんにゃく式戌亥とこver1.0\n",
    "drwxr-xr-x     3 31004 31000      73 Dec 24 00:20 3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00\n",
    "drwxr-xr-x     3 31004 31000      40 Dec 24 00:20 3d.nicovideo__10029__大阪ステージ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f260",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca51eae",
   "metadata": {},
   "source": [
    "## Filtering Dataset (1)\n",
    "\n",
    "For convinience, I used projects which used `.pmx`, `.pmd` or `.vrm` file.\n",
    "\n",
    "After running the cells, I had about 30000 projects supporting `.pmd`, `.pmx`, or `.vrm` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574a0c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 30155/30155 [00:02<00:00, 14299.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30155 25715 3824 616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def find_model_in_dir(dir_model: str):\n",
    "    \"\"\" searches if dir_model has loadable file\n",
    "\n",
    "    Args:\n",
    "        dir_model: root dir to find loadable file\n",
    "\n",
    "    Returns:\n",
    "        result: Boolean. True if exists, else False\n",
    "        path_model: str. if result is true, valid model path is given. Else returns ''\n",
    "\n",
    "    \"\"\"\n",
    "    result = False\n",
    "    result_path = ''\n",
    "    for root, subdirs, files in os.walk(dir_model):\n",
    "        for file in files:\n",
    "            path_model = os.path.join(root, file)\n",
    "            if file.endswith('.pmx'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "            elif file.endswith('.pmd'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "            elif file.endswith('.vrm'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "\n",
    "        if result:\n",
    "            break\n",
    "\n",
    "    return result, result_path\n",
    "\n",
    "\n",
    "def find_valid_dirs(dir_root: str):\n",
    "    \"\"\" finds subdir names which contains loadable files (.pmx, .pmd, .vrm)\n",
    "\n",
    "    Args:\n",
    "        dir_root: root dir to search\n",
    "        path_save: path to save indices\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    models = sorted([os.path.join(dir_root, file) for file in os.listdir(dir_root)\n",
    "                     if os.path.isdir(os.path.join(dir_root, file))])\n",
    "\n",
    "    pmxs = []\n",
    "    pmds = []\n",
    "    vrms = []\n",
    "\n",
    "    for dir_model in tqdm(models):\n",
    "        result_bool, result_path = find_model_in_dir(dir_model)\n",
    "        if result_bool:\n",
    "            if result_path.endswith('.pmx'):\n",
    "                pmxs.append(dir_model)\n",
    "            elif result_path.endswith('.pmd'):\n",
    "                pmds.append(dir_model)\n",
    "            elif result_path.endswith('.vrm'):\n",
    "                vrms.append(dir_model)\n",
    "\n",
    "    print(len(models), len(pmxs), len(pmds), len(vrms))\n",
    "\n",
    "    valid_list = sorted(pmxs + pmds + vrms)\n",
    "    return valid_list\n",
    "\n",
    "\n",
    "dir_root = './data/3d_models/models'\n",
    "dir_projects = find_valid_dirs(dir_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d157ed8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7aa0fe",
   "metadata": {},
   "source": [
    "## Filtering dataset (2)\n",
    "\n",
    "* First, non-human shaped models should be filtered out.\n",
    "* Second, since original *Talking Head Anime* used 6 parameters(`Left eye`, `Right eye`, `Mouth`, `Head X`, `Head Y`, `Neck Z`), models not containing such keys should be filtered out.\n",
    "    * Although `.pmx`, `.pmd`, `.vrm` is common and standard-like model and it is easy to figure out that using `あ`, `ウィンク`, `ウィンク右` and `頭`(or `頸`) is enough, but...\n",
    "    * Some models use different keys. (e.g. some are translated to other language that is not `janapese`(standard)) \n",
    "    * To make sure, we'll extract shape keys and pose keys from all model files and analyze them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096e740",
   "metadata": {},
   "source": [
    "### Finding all models from projects\n",
    "\n",
    "Some projects include more than one models. (Usually cloth or accessories changed/added)\n",
    "\n",
    "We find all `.pmd`, `.pmx`, `.vrm` files to enlarge training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119a21b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 1467.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30155 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def find_all_models(dir_projects):\n",
    "    all_models = []\n",
    "    for dir_project in tqdm(dir_projects):\n",
    "        models_in_dir = []\n",
    "\n",
    "        for root, subdirs, files in os.walk(dir_project):\n",
    "            for file in files:\n",
    "                path_model = os.path.abspath(os.path.join(root, file))\n",
    "                extension = file.rsplit('.', 1)[-1].lower()\n",
    "                if extension == 'pmd' or extension == 'pmx' or extension == 'vrm':\n",
    "                    if path_model not in models_in_dir:\n",
    "                        models_in_dir.append(path_model)\n",
    "        \n",
    "        all_models.extend(models_in_dir)\n",
    "\n",
    "    return all_models\n",
    "\n",
    "path_models = find_all_models(dir_projects[:20])\n",
    "print(len(dir_projects), len(path_models))\n",
    "\n",
    "with open('data/3d_models/all_models.txt', 'w', encoding='utf-8') as f:\n",
    "    write_data = [item+'\\n' for item in path_models]\n",
    "    f.writelines(write_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c78b1",
   "metadata": {},
   "source": [
    "### Saving models into .blend files\n",
    "\n",
    "While extracting shape keys and pose keys, saving each model files into `.blend` file is helpful for later convenient use.\n",
    "\n",
    "* `.blend` files can be loaded faster than loading from scratch with addons. \n",
    "* If once saved as `.blend` format, addons are not needed when loading & rendering `.blend` file.\n",
    "\n",
    "\n",
    "\n",
    "**!!Before running!!** \n",
    "* Check `utils/data/run_blends.py` and `utils/data/save_to_blends.py` and try to adjust number of processes available with your device.( Line number ?? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c686ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38it [03:07,  4.92s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m utils.data.run_blends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657b543",
   "metadata": {},
   "source": [
    "### Analysis of shape keys, pose keys\n",
    "\n",
    "First, pair each key and models.\n",
    "\n",
    "#### Find all .blend files\n",
    "\n",
    "Using successfully saved `.blend` files helps to keep away from unexpected bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ed8059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 6394.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# find all blend files\n",
    "\n",
    "def find_all_blends(blend_dir):\n",
    "    all_blends = []\n",
    "    dirnames = os.listdir(blend_dir)\n",
    "    for dirname in tqdm(dirnames):\n",
    "        dir_model = os.path.join(blend_dir, dirname)\n",
    "        blends_in_dir = []\n",
    "        \n",
    "        for root, subdirs, files in os.walk(dir_model):    \n",
    "            for file in files:\n",
    "                path_model = os.path.join(root, file)\n",
    "                extension = file.rsplit('.', 1)[-1].lower()\n",
    "                if extension == 'blend':\n",
    "                    if path_model not in blends_in_dir:\n",
    "                        blends_in_dir.append(path_model)\n",
    "        \n",
    "        all_blends.extend(blends_in_dir)\n",
    "\n",
    "    return all_blends\n",
    "\n",
    "all_blends = find_all_blends(blend_dir='data/3d_models/blends')\n",
    "print(len(all_blends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2af1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 3277.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_keys(path_blends):\n",
    "    shapes = defaultdict(list)\n",
    "    poses = defaultdict(list)\n",
    "    \n",
    "    for path_blend in tqdm(path_blends):\n",
    "        path_shape = path_blend[:-6] + '.shape.txt'\n",
    "        with open(path_shape, 'r', encoding='utf-8') as f:\n",
    "            shape_keys = f.readlines()\n",
    "        for line in shape_keys:\n",
    "            key = line.strip()\n",
    "            shapes[key].append(path_blend)\n",
    "            \n",
    "        path_pose = path_blend[:-6] + '.pose.txt'            \n",
    "        with open(path_pose, 'r', encoding='utf-8') as f:\n",
    "            pose_keys = f.readlines()\n",
    "        for line in pose_keys:\n",
    "            key = line.strip()\n",
    "            poses[key].append(path_blend)\n",
    "    \n",
    "    return shapes, poses\n",
    "\n",
    "shapes, poses = count_keys(all_blends)\n",
    "shape_counts = [f'{key}, {len(value)}\\n' for key, value in shapes.items()]\n",
    "shape_counts = sorted(shape_counts, key=lambda x: int(x.strip().rsplit(', ')[-1]), reverse=True)\n",
    "with open('data/3d_models/all_shapes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(shape_counts)\n",
    "\n",
    "\n",
    "pose_counts = [f'{key}, {len(value)}\\n' for key, value in poses.items()]\n",
    "pose_counts = sorted(pose_counts, key=lambda x: int(x.strip().rsplit(', ')[-1]), reverse=True)\n",
    "with open('data/3d_models/all_poses.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(pose_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434a0625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis, 38\n",
      "まばたき, 20\n",
      "い, 18\n",
      "う, 18\n",
      "え, 18\n",
      "笑い, 18\n",
      "怒り, 16\n",
      "あ, 14\n",
      "お, 14\n",
      "なごみ, 14\n",
      "########\n",
      "全ての親, 25\n",
      "センター, 25\n",
      "上半身, 21\n",
      "首, 21\n",
      "頭, 21\n",
      "肩.L, 21\n",
      "腕.L, 21\n",
      "肩.R, 21\n",
      "腕.R, 21\n",
      "下半身, 21\n"
     ]
    }
   ],
   "source": [
    "!cat data/3d_models/all_shapes.txt | head -10\n",
    "print('########')\n",
    "!cat data/3d_models/all_poses.txt | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089359a",
   "metadata": {},
   "source": [
    "As expected, `あ`, `ウィンク`, `ウィンク右` and `頭` is the most general keys and using them would be enough.\n",
    "* `あ` is much more used than `a` and amount of `a` could be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262bcbc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23702e8",
   "metadata": {},
   "source": [
    "## Filtering dataset (3)\n",
    "\n",
    "It is not guaranteed for a model to properly work with `あ`, `ウィンク`, `ウィンク右` and `頭`.\n",
    "\n",
    "For example, somes models may move its' left eye with key(eye on the right when rendered at image) `ウィンク右`(meaning right wink), while others may move models' right eye.\n",
    "\n",
    "Filtering and adjusting them is important proess in dataset generation. Sadly, such filtering could be best done with pure human effort. In this process, we render sample images from models and classify those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e220768",
   "metadata": {},
   "source": [
    "#### Generating Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2411731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "all_valid_blends = list(set.intersection(set(shapes['あ']), set(shapes['ウィンク']), set(shapes['ウィンク右']), set(poses['頭'])))\n",
    "with open('data/3d_models/all_valid_blends.txt', 'w', encoding='utf-8') as f:\n",
    "    write_lines = [item+'\\n' for item in all_valid_blends]\n",
    "    f.writelines(write_lines)\n",
    "print(len(all_valid_blends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bca8a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10it [04:35, 27.50s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m utils.data.run_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af93d873",
   "metadata": {},
   "source": [
    "#### Checking Generated Sample Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14f995",
   "metadata": {},
   "source": [
    "**TODO: I'll try to make this runnable at ipynb.**\n",
    "\n",
    "I used custom filtering helper tool to label the data.\n",
    "\n",
    "You may use `python -m utils.data.filter_tool3` if you have gui in your device. Else, you should use your own method to check the samples.\n",
    "\n",
    "1. run `python -m utils.data.filter_tool3` at the root of the project.\n",
    "2. If the model is closing left eye at the second image, PRESS l.\n",
    "3. If the model is closing right eye at the second image, PRESS r.\n",
    "4. If there is some error on rendered images, PRESS any other key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4218ff",
   "metadata": {},
   "source": [
    "After checking sample images, you get `data/3d_models/filtered_idxs.txt`.\n",
    "\n",
    "Now we will generate training dataset based on the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f267d4",
   "metadata": {},
   "source": [
    "## Generating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecf59a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0it [00:00, ?it/s]ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/talking_head_anime_2/utils/data/script3.py\", line 89, in <module>\n",
      "    main2()\n",
      "  File \"/root/talking_head_anime_2/utils/util.py\", line 14, in wrapper\n",
      "    return func(*a, **ka)\n",
      "  File \"/root/talking_head_anime_2/utils/data/script3.py\", line 28, in main2\n",
      "    path_blend, label = metadata[internal_idx].strip().split('|')\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n",
      "^C\n",
      "0it [00:07, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n",
      "    item = self._items.popleft()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/talking_head_anime_2/utils/data/generate_dataset.py\", line 28, in <module>\n",
      "    list(range(len(metadata))), cycle([path_metadata])\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/site-packages/tqdm/std.py\", line 1180, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n",
      "    self._cond.wait(timeout)\n",
      "  File \"/opt/conda/envs/blender_py37/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m utils.data.generate_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
