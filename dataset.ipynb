{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e42ff28",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "You can train Talking Head Anime with two different type of datasets:\n",
    "\n",
    "1. Images Dataset (recommended)\n",
    "2. 3D-models Dataset\n",
    "\n",
    "If you don't have appropriate dataset, you may want to follow instructions below or write your own dataset code with your data.\n",
    "\n",
    "If you have any, or have own code for your dataset, you may skip these.\n",
    "\n",
    "### Images dataset:\n",
    "\n",
    "* set of images consist of (model_base, model_shaped, model_shaped_rotated) pairs.\n",
    "* Detailed description of pairs:\n",
    "    * model_base: Image of model with rest(base) pose. `base.png`\n",
    "    * model_shaped: Image of model with its face parts' shape changed. `shape_0.57_0.0_0.5.png`\n",
    "    * model_shaped_rotated: Image of model of `model_shaped`'s head rotated with XYZ\n",
    "      axis.`pose_0.57_0.0_0.5_0.41_-0.68_1.png`\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th> Type </th>\n",
    "    <th width=256>Model base</th>\n",
    "    <th width=256>Model shaped</th>\n",
    "    <th width=256>Model shaped rotated</th> \n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th> Description </th>\n",
    "    <td> Rendered Image of a 3d model with rest pose </td>\n",
    "    <td> Rendered Image of a 3d model with its face expression changed. <br> Mouth: 0.57 open, Left eye: 0.0 closed, Right eye: 0.5 closed. </td>\n",
    "    <td> Rendered Image of a 3d model with its face expression changed, and then head rotated. <br> Mouth: 0.57 open, Left eye: 0.0 closed, Right eye: 0.5 closed. <br> Head rotated  with x axis: 0.41 pi/2, y_axis: -0.68 pi/2, z_axis: 1 pi/2 </td>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "    <th> Image </th>\n",
    "    <td><img src=\"src/images/base.png?v=1\" width=256/></td> \n",
    "    <td><img src=\"src/images/shape_0.57_0.0_0.5.png\" width=256/></td> \n",
    "    <td><img src=\"src/images/pose_0.57_0.0_0.5_0.41_-0.68_1.png\" width=256/></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "### 3D-models dataset:\n",
    "\n",
    "Note that 3D-models dataset may suffer with extermely low speed when training.\n",
    "\n",
    "* Set of models where each files' extension is one of `.pmx`, `.pmd` or `.vrm`.\n",
    "\n",
    "Example:\n",
    "```\n",
    "[dhchoi@localhost 3d_models]$ cat all_blends.txt | head -3\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10003__こんにゃく式戌亥とこver1.0/こんにゃく式戌亥とこver1.0/戌亥とこ.pmx\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール(帽子無し).pmx\n",
    "/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール.pmx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a0fd1",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38d281",
   "metadata": {},
   "source": [
    "## Downloading 3D Models\n",
    "\n",
    "Here, we'll download 3D models and filter usable models for Talking Head Anime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb800c",
   "metadata": {},
   "source": [
    "### Downloading 3D models\n",
    "\n",
    "I batch-crawled 3d models from [3d.nicovideo.jp](3d.nicovideo.jp) and [bowlroll.net](bowlroll.net) to `./data/3d_models/models`.  \n",
    "\n",
    "Each models(or projects) are seperated into directories. Naming convention is not a big problem unless you(and your code) can classify those.\n",
    "\n",
    "**Since there must exist copyright issue, I will not provide the download script.**\n",
    "\n",
    "Downloading the models took about 1~2 days, resulting with about 60000 projects.\n",
    "\n",
    "Example:\n",
    "```\n",
    "(blender_py37) root@d0277a12bc8c:~/talking_head_anime_2# ll data/3d_models/models/ | head -10\n",
    "total 4392\n",
    "drwxr-xr-x 30157 31004 31000 1789952 Jan 28 18:31 ./\n",
    "drwxr-xr-x     9 31004 31000     324 Feb  9 02:31 ../\n",
    "drwxr-xr-x     3 31004 31000      60 Dec 24 00:20 3d.nicovideo__10002__ニュイ・ソシエール(部屋着)/\n",
    "drwxr-xr-x     3 31004 31000      58 Dec 24 00:20 3d.nicovideo__10003__こんにゃく式戌亥とこver1.0/\n",
    "drwxr-xr-x     3 31004 31000      73 Dec 24 00:20 3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/\n",
    "drwxr-xr-x     3 31004 31000      40 Dec 24 00:20 3d.nicovideo__10029__大阪ステージ/\n",
    "drwxr-xr-x     3 31004 31000      35 Dec 24 00:20 3d.nicovideo__10031__後鬼_ver0.2/\n",
    "drwxr-xr-x     3 31004 31000      55 Dec 24 00:20 3d.nicovideo__10032__つかさ式満潮アリスVer1.0/\n",
    "drwxr-xr-x     3 31004 31000      63 Dec 24 00:20 3d.nicovideo__10034__ﾏﾝﾊｯﾀﾝP式雨森小夜%2Bver1.1/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f260",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca51eae",
   "metadata": {},
   "source": [
    "## Filtering Dataset (1)\n",
    "\n",
    "For convinience, I used projects which used `.pmx`, `.pmd` or `.vrm` file.\n",
    "\n",
    "After running the cells, I had about 30000 projects supporting `.pmd`, `.pmx`, or `.vrm` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574a0c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 30155/30155 [00:02<00:00, 13111.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30155 25715 3824 616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "def find_model_in_dir(dir_model: str):\n",
    "    \"\"\" searches if dir_model has loadable file\n",
    "\n",
    "    Args:\n",
    "        dir_model: root dir to find loadable file\n",
    "\n",
    "    Returns:\n",
    "        result: Boolean. True if exists, else False\n",
    "        path_model: str. if result is true, valid model path is given. Else returns ''\n",
    "\n",
    "    \"\"\"\n",
    "    result = False\n",
    "    result_path = ''\n",
    "    for root, subdirs, files in os.walk(dir_model):\n",
    "        for file in files:\n",
    "            path_model = os.path.join(root, file)\n",
    "            if file.endswith('.pmx'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "            elif file.endswith('.pmd'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "            elif file.endswith('.vrm'):\n",
    "                result = True\n",
    "                result_path = path_model\n",
    "                break\n",
    "\n",
    "        if result:\n",
    "            break\n",
    "\n",
    "    return result, result_path\n",
    "\n",
    "\n",
    "def find_valid_dirs(dir_root: str):\n",
    "    \"\"\" finds subdir names which contains loadable files (.pmx, .pmd, .vrm)\n",
    "\n",
    "    Args:\n",
    "        dir_root: root dir to search\n",
    "        path_save: path to save indices\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    models = sorted([os.path.join(dir_root, file) for file in os.listdir(dir_root)\n",
    "                     if os.path.isdir(os.path.join(dir_root, file))])\n",
    "\n",
    "    pmxs = []\n",
    "    pmds = []\n",
    "    vrms = []\n",
    "\n",
    "    for dir_model in tqdm(models):\n",
    "        result_bool, result_path = find_model_in_dir(dir_model)\n",
    "        if result_bool:\n",
    "            if result_path.endswith('.pmx'):\n",
    "                pmxs.append(dir_model)\n",
    "            elif result_path.endswith('.pmd'):\n",
    "                pmds.append(dir_model)\n",
    "            elif result_path.endswith('.vrm'):\n",
    "                vrms.append(dir_model)\n",
    "\n",
    "    print(len(models), len(pmxs), len(pmds), len(vrms))\n",
    "\n",
    "    valid_list = sorted(pmxs + pmds + vrms)\n",
    "    return valid_list\n",
    "\n",
    "\n",
    "dir_root = './data/3d_models/models'\n",
    "dir_projects = find_valid_dirs(dir_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d157ed8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7aa0fe",
   "metadata": {},
   "source": [
    "## Filtering dataset (2)\n",
    "\n",
    "Among the models, We need to filter out human models only, and get data of which key moves each face parts. (In fact, it is well-known or easy to figure out that using `あ`, `ウィンク`, `ウィンク右` and `頭`(or `頸`) is enough, but I'll go on for this to make sure.)\n",
    "\n",
    "To do so, I'll extract shape keys and pose keys from model files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096e740",
   "metadata": {},
   "source": [
    "### Finding all models from projects\n",
    "\n",
    "Some projects include more than one models. (Usually cloth or accessories changed/added)\n",
    "\n",
    "We find all `.pmd`, `.pmx`, `.vrm` files to enlarge training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119a21b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 721.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30155 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def find_all_models(dir_projects):\n",
    "    all_models = []\n",
    "    for dir_project in tqdm(dir_projects):\n",
    "        models_in_dir = []\n",
    "\n",
    "        for root, subdirs, files in os.walk(dir_project):\n",
    "            for file in files:\n",
    "                path_model = os.path.abspath(os.path.join(root, file))\n",
    "                extension = file.rsplit('.', 1)[-1].lower()\n",
    "                if extension == 'pmd' or extension == 'pmx' or extension == 'vrm':\n",
    "                    if path_model not in models_in_dir:\n",
    "                        models_in_dir.append(path_model)\n",
    "        \n",
    "        all_models.extend(models_in_dir)\n",
    "\n",
    "    return all_models\n",
    "\n",
    "path_models = find_all_models(dir_projects[:3])\n",
    "print(len(dir_projects), len(path_models))\n",
    "\n",
    "with open('data/3d_models/all_models.txt', 'w', encoding='utf-8') as f:\n",
    "    write_data = [item+'\\n' for item in path_models]\n",
    "    f.writelines(write_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d390b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10002__ニュイ・ソシエール(部屋着)/ニュイ・ソシエール(部屋着)/ニュイ・ソシエール(部屋着).pmx.blend', '/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10003__こんにゃく式戌亥とこver1.0/こんにゃく式戌亥とこver1.0/戌亥とこ.pmx.blend', '/root/talking_head_anime_2/data/3d_models/blends/3d.nicovideo__10024__(にじさんじ)ニュイ・ソシエールVer1.00/(にじさんじ)ニュイ・ソシエールVer1.00/models/ニュイ・ソシエール(帽子無し).pmx.blend']\n"
     ]
    }
   ],
   "source": [
    "path_blends = [item.replace('data/3d_models/models', 'data/3d_models/blends')+'.blend'\n",
    "               for item in path_models]\n",
    "print(path_blends[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c78b1",
   "metadata": {},
   "source": [
    "### Saving models into .blend files\n",
    "\n",
    "While extracting shape keys and pose keys, I save each model files into `.blend` files for later convenient use.\n",
    "\n",
    "`.blend` files can be loaded faster than loading from scratch with addons. Also, if once saved as `.blend` format, we don't need to load necessary addons after loading `.blend` file.\n",
    "\n",
    "\n",
    "\n",
    "**!!Before running!!** \n",
    "\n",
    "* Check `utils/data/run_blends.py` and `utils/data/save_to_blends.py` and try to adjust number of processes available with your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c686ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4528:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5007:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2495:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "4it [00:32,  8.11s/it]\n"
     ]
    }
   ],
   "source": [
    "!python -m utils.data.run_blends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657b543",
   "metadata": {},
   "source": [
    "### Analysis of shape keys, pose keys\n",
    "\n",
    "First, we pair each key and models with the key.\n",
    "\n",
    "#### Find all .blend files\n",
    "\n",
    "We'll use successfully saved `.blend` files only.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ed8059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 2589.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# find all blend files\n",
    "\n",
    "def find_all_blends(blend_dir):\n",
    "    all_blends = []\n",
    "    dirnames = os.listdir(blend_dir)\n",
    "    for dirname in tqdm(dirnames):\n",
    "        dir_model = os.path.join(blend_dir, dirname)\n",
    "        blends_in_dir = []\n",
    "        \n",
    "        for root, subdirs, files in os.walk(dir_model):    \n",
    "            for file in files:\n",
    "                path_model = os.path.join(root, file)\n",
    "                extension = file.rsplit('.', 1)[-1].lower()\n",
    "                if extension == 'blend':\n",
    "                    if path_model not in blends_in_dir:\n",
    "                        blends_in_dir.append(path_model)\n",
    "        \n",
    "        all_blends.extend(blends_in_dir)\n",
    "\n",
    "    return all_blends\n",
    "\n",
    "all_blends = find_all_blends(blend_dir='data/3d_models/blends_220222')\n",
    "print(len(all_blends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c92a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 1127.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_keys(path_blends):\n",
    "    shapes = defaultdict(list)\n",
    "    poses = defaultdict(list)\n",
    "    \n",
    "    for path_blend in tqdm(path_blends):\n",
    "        path_shape = path_blend[:-6] + '.shape.txt'\n",
    "        with open(path_shape, 'r', encoding='utf-8') as f:\n",
    "            shape_keys = f.readlines()\n",
    "        for line in shape_keys:\n",
    "            key = line.strip()\n",
    "            shapes[key].append(path_blend)\n",
    "            \n",
    "        path_pose = path_blend[:-6] + '.pose.txt'            \n",
    "        with open(path_pose, 'r', encoding='utf-8') as f:\n",
    "            pose_keys = f.readlines()\n",
    "        for line in pose_keys:\n",
    "            key = line.strip()\n",
    "            poses[key].append(path_blend)\n",
    "    \n",
    "    return shapes, poses\n",
    "\n",
    "shapes, poses = count_keys(all_blends)\n",
    "shape_counts = [f'{key}, {len(value)}\\n' for key, value in shapes.items()]\n",
    "shape_counts = sorted(shape_counts, key=lambda x: int(x.strip().rsplit(', ')[-1]), reverse=True)\n",
    "with open('data/3d_models/all_shapes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(shape_counts)\n",
    "\n",
    "\n",
    "pose_counts = [f'{key}, {len(value)}\\n' for key, value in poses.items()]\n",
    "pose_counts = sorted(pose_counts, key=lambda x: int(x.strip().rsplit(', ')[-1]), reverse=True)\n",
    "with open('data/3d_models/all_poses.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(pose_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b549ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/3d_models/all_shapes.txt | head -10\n",
    "!cat data/3d_models/all_poses.txt | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6fb05",
   "metadata": {},
   "source": [
    "As expected, `あ`, `ウィンク`, `ウィンク右` and `頭` is the most general keys and using them would be enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8344884",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc04c40",
   "metadata": {},
   "source": [
    "## Filtering dataset (3)\n",
    "\n",
    "It is not guaranteed for a model to properly work with our desired keys.\n",
    "\n",
    "For example, somes models may move its' left eye with key(eye on the right when rendered at image) `ウィンク右`(meaning right wink), while others may move models' right eye.\n",
    "\n",
    "Filtering and adjusting them is important proess in dataset generation. Sadly, such filtering could be best done with pure human effort. In this process, we render sample images from models and classify those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "python make_dataset.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
